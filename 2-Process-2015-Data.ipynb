{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process 2015 Data\n",
    "\n",
    "Goals:\n",
    "- Use the 2015 MAUDE data to create a sample dataset for experimentation\n",
    "\n",
    "Steps:\n",
    "1. Identify all common data files\n",
    "\n",
    "|File                    |Description|Required|\n",
    "|------------------------|-----------|--------|\n",
    "|`mdrfoithru2021.zip`    |Master Record through 2021|X|\n",
    "|`patientthru2021.zip`   |Patient Record through 2021|X|\n",
    "|`foitextchange.zip`     |Narrative data updates: changes to existing narrative data and additional narrative data for existing base records|X|\n",
    "|`patientproblemcode.zip`|Device Data for patientproblemcode||\n",
    "|`patientproblemdata.zip`|Patient Problem Data||\n",
    "|`patientchange.zip`     |MAUDE Patient data updates: changes to existing Base data||\n",
    "|`mdrfoichange.zip`      |MAUDE Base data updates: changes to existing Base data||\n",
    "|`devicechange.zip`      |Device data updates: changes to existing Device data and additional Device data for existing Base records||\n",
    "|`deviceproblemcodes.zip`|Device Problem Data||\n",
    "|`foidevproblem.zip`     |Device Data for foidevproblem||\n",
    "\n",
    "2. Identify all 2015 data files\n",
    "\n",
    "|File                    |Description|Required|\n",
    "|------------------------|-----------|--------|\n",
    "|`device2015.zip`        |Device Data for 2015|X|\n",
    "|`foitext2015.zip`       |Narrative Data for 2015|X|\n",
    "\n",
    "3. Create databases for each data type\n",
    "4. Create a merged dataset using joins for each Master Data Record ID in the 2015 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip data files\n",
    "Goals:\n",
    "- _*(COMPLETE)*_ Unzip downloaded data files to extract the archived `.txt` file\n",
    "\n",
    "The following Python code completes these steps:\n",
    "1. Identify the data directory, working directory, and data files\n",
    "1. Create the working directory if needed\n",
    "1. Unzip the data files into the working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipping device2015.zip\n",
      "Unzipping foitextchange.zip\n",
      "Unzipping patientthru2021.zip\n",
      "Unzipping foitext2015.zip\n",
      "Unzipping mdrfoithru2021.zip\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "import os\n",
    "\n",
    "# Identify the data directory, working directory, and data files\n",
    "data_directory = './data'\n",
    "working_directory = './2015'\n",
    "data_files = ['device2015.zip', 'foitextchange.zip', 'patientthru2021.zip',\n",
    "              'foitext2015.zip', 'mdrfoithru2021.zip']\n",
    "\n",
    "\n",
    "# Create the working directory if needed\n",
    "try:\n",
    "    os.makedirs(working_directory, exist_ok = True)\n",
    "except OSError as error:\n",
    "    print(f\"Error creating {working_directory}: {error}\")\n",
    "\n",
    "# Unzip the data files into the working directory\n",
    "for i in data_files:\n",
    "    print(f\"Unzipping {i}\")\n",
    "    with ZipFile(f\"{data_directory}/{i}\", \"r\") as zip:\n",
    "        zip.extractall(f\"{working_directory}\")\n",
    "\n",
    "print(\"Unzip complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a database for each data file\n",
    "Goals:\n",
    "- Read the data files into dataframes\n",
    "- Write the dataframes to tables in an SQLite database\n",
    "\n",
    "The following Python code completes these steps:\n",
    "1. Create a database\n",
    "1. Process each file in the working directory\n",
    "1. Get the file path and the base name of the file by removing '.txt'\n",
    "1. Create a dataframe for the file using Pandas, reading each file as a comma seperated values (TSV) file, using the pipe seperator\n",
    "1. Set the MDR_REPORT_KEY as the index for the dataframe\n",
    "1. Write the dataframe to a new SQLite table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing foitextChange.txt\n",
      "Processing foitext2015.txt\n",
      "Processing DEVICE2015.txt\n",
      "Processing patientThru2021.txt\n",
      "Processing mdrfoiThru2021.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 11971429: expected 82 fields, saw 83\\n'\n",
      "/var/folders/12/zfq9jlbn7pj6kffqfjsrs8fc0000gp/T/ipykernel_98545/4054705136.py:23: DtypeWarning: Columns (0,1,5,6,12,13,16,17,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,74,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "# Create a database\n",
    "db = sqlite3.connect(f\"{working_directory}/database.sqlite3\")\n",
    "\n",
    "# Process each file in the working directory\n",
    "for root, dirs, files in os.walk(working_directory):\n",
    "   for file_name in files:\n",
    "\n",
    "      # Only process '.txt' files...\n",
    "      if file_name.endswith(\".txt\"):\n",
    "         print(f\"Processing {file_name}\")\n",
    "         \n",
    "         # Get the file path and the base name of the file by removing '.txt'\n",
    "         file_path = os.path.join(root, file_name)\n",
    "         base_name = file_name.replace('.txt','')\n",
    "\n",
    "         # Create a dataframe for the file\n",
    "         df = pd.read_csv(file_path, \n",
    "            sep=\"|\", \n",
    "            encoding=\"ISO-8859-1\", \n",
    "            on_bad_lines='warn', \n",
    "            quoting=csv.QUOTE_NONE)\n",
    "\n",
    "         # Set the MDR_REPORT_KEY as the index for the dataframe\n",
    "         df.set_index('MDR_REPORT_KEY', inplace=True)\n",
    "         \n",
    "         # Write the dataframe to a new SQLite table\n",
    "         df.to_sql(base_name, db, if_exists=\"replace\")\n",
    "\n",
    "         # Remove the dataframe in an attempt to free up memory\n",
    "         del df\n",
    "\n",
    "print(\"Database creation complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('VSCode')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0df23e0b8587652e8947bf433502af00ecfb3462d59e71e7bba71c0280b5fb19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
